# Testing con JUnit 5

Esta es una guia que cree a partir del curso [Testing Spring Beginner to Guru](https://www.udemy.com/testing-spring-boot-beginner-to-guru/?couponCode=GITHUB_REPO). En este mismo archivo voy anotando lo aprendido y, m√°s importante, valoraciones personales de acuerdo a mi experiencia.

El c√≥digo est√° basado en [Spring Framework Pet Clinic project](https://github.com/spring-petclinic/spring-framework-petclinic) que es un proyecto de referencia que usa la arquitectura de 3 capas sin Spring Boot.

## Setup
### Requerimientos
* Java 11 o superior. Las versiones anteriores no est√°n probadas.
* Maven 3.6.0 o superior

### Como correr la aplicaci√≥n
After cloning this repo, from the project root run:
```text
./mvnw jetty:run-war
```

## Tabla de Contenidos
- [Testing Spring Boot: Beginner to Guru](#testing-con-junit-5)
  - [Tabla de Contenidos](#tabla-de-contenidos)
  - [Conceptos importantes](#conceptos-importantes)
    - [¬øPor qu√© es importante el testing?](#-por-qu√©-es-importante-el-testing)
    - [Unit tests](#%EF%B8%8F-unit-tests)
    - [Integration tests](#-integration-tests)
    - [Functional tests](#-functional-tests)
    - [Errores comunes](#-errores-comunes)
    - [Tips](#-tips)
    - [Code coverage](#code-coverage)
  - [Test-Driven Development (TDD)](#test-driven-development-tdd)
    - [Ciclo de TDD](#ciclo-de-tdd)
    - [Tips](#-tips-1)
  - [JUnit 5](#junit-5)
    - [Configuraci√≥n](#configuraci√≥n)
    - [Tips](#-tips)
    - [Probar las excepciones esperadas](#probar-las-excepciones-esperadas)
    - [Testing timeouts](#testing-timeouts)
    - [Ejecuci√≥n opcional de tests](#ejecuci√≥n-opcional-de-tests)
      - [Assumptions](#assumptions)
  - [Testing avanzado (con JUnit)](#testing-avanzado-con-junit)
  - [@RepeatedTest](#repeatedtest)
    - [Casos de uso](#casos-de-uso)
  - [@ParameterizedTest](#parameterizedtest)
    - [Usando un archivo CSV como fuente de datos](#usando-un-archivo-csv-como-fuente-de-datos)
    - [Usando m√©todos como fuente de datos](#usando-m√©todos-como-fuente-de-datos)
  - [Tests unitarios vs Tests de Integraci√≥n](#tests-unitarios-vs-tests-de-integraci√≥n)
  - [Tipos de test seg√∫n su capa (Controller, service, etc)](#tipos-de-test-seg√∫n-su-capa-controller-service-etc)
    - [Service (Business Logic) o Casos de uso (UseCase en arquitectura hexagonal)](#service-business-logic-o-casos-de-uso-usecase-en-arquitectura-hexagonal)
    - [Controller (Request & Response format)](#controller-request--response-format)
        - [Links de inter√©s](#links-de-interes)
    - [View (Front-end)](#view-front-end)
    - [API Client (o Adapter)](#api-client-o-adapter)
  - [Extensiones de JUnit](#extensiones-de-junit)
  - [Ejecuci√≥n de Tests](#ejecuci√≥n-de-tests)
  - [Mockito](#mockito)
    - [Tipos de Mocks](#tipos-de-mocks)
    - [M√°s terminolog√≠a](#m√°s-terminolog√≠a)
    - [Ejemplos B√°sicos](#ejemplos-b√°sicos)
    - [Inyectando dependencias y retornando valores con *when*](#inyectando-dependencias-y-retornando-valores-con-when)
  - [Behaviour Driven Development (BDD)](#behaviour-driven-development-bdd)
  - [Mockito avanzado](#mockito-avanzado)
    - [Excepciones](#excepciones)
    - [Capturar argumentos con *Argument Captor*](#capturar-argumentos-con-argument-captor)
  - [Dudas](#-dudas)
    - [¬øC√≥mo pruebo un m√©todo privado?](#%EF%B8%8F-c√≥mo-pruebo-un-m√©todo-privado)
      - [Usando Java Reflection](#usando-java-reflection)
      - [Usando Springboot](#usando-springboot)
    - [¬øQu√© sentido tiene testear un Service que lo √∫nico que hace es llamar a un Repository?](#%EF%B8%8F-qu√©-sentido-tiene-testear-un-service-que-lo-√∫nico-que-hace-es-llamar-a-un-repository)
  - [Links a art√≠culos interesantes](#links-a-art√≠culos-interesantes)

## Conceptos importantes

### ‚ùî ¬øPor qu√© es importante el testing?
Ya s√©, seguramente est√°s pensando que la pregunta es est√∫pida o que sos muy bueno programando y no te hace falta probar tu c√≥digo porque sab√©s que va andar. Nada m√°s alejado de la realidad...

Primero que nada, a programar se aprende programando y, ser un **buen programador** es, en gran parte, ser **un programador con buenos h√°bitos**. Por tanto, si no prob√°s tu c√≥digo no sos un buen programador.

Segundo, al principio puede que no resulte f√°cil ver, en t√©rminos de costo/beneficio, las ventajas del testing. En especial, el testing sobre el c√≥digo. Por esta raz√≥n voy a empezar nombrando **las desventajas** que trae NO hacer testing apropiadamente:
1. Incertidumbre sobre si un escenario particular est√° probado y nuestro sistema lo contempla adecuadamente o falla.
2. A medida que crece el proyecto, el mismo se vuelve m√°s complejo y dificil de mantener.
3. El crecimiento acelerado y con un equipo trabajando en simult√°neo, sin el testing adecuado es propenso a errores y a bajar la calidad del c√≥digo.
4. Aunque seamos muy cuidadosos, puede que un compa√±ero nuestro a√±ada una funcionalidad que entra en conflicto con la nuestra y nos percatemos del error hasta que nos explota en la cara.
5. Baja calidad del c√≥digo: escribir tests no solo nos asegura que nuestro c√≥digo est√° probado sino que nos fuerza a pensar y escribir nuestro c√≥digo de manera que podamos testearlo, y en general, esto conduce a la generaci√≥n de c√≥digo m√°s s√≥lido.
6. Tests de regresi√≥n manuales: a√±adimos un cambio en nuestro c√≥digo pero debemos asegurarnos que sea *retrocompatible* y no rompa escenarios anteriores. Sino tenemos tests de c√≥digo autom√°tizados, debemos  que ejecutar *tests funcionales (TD y TE)* manualmente. Esto hace que el **tiempo que nos lleva probar nuestro sistema aumente exponencialmente**.
7. Un cambio menor hace un desastre: muchas veces terminamos nuestro desarrollo, comenzamos con las pruebas y durante ellas detectamos un peque√±o error que decimos "Ah, esto lo soluciono en un segundo con 2 l√≠neas de c√≥digo" y realizamos el cambio pero no lo probamos porque "no hace falta". Luego nos enteramos del error que introdujimos cuando ya es tarde...
8. Miedo al refactor: tengo que hacer una modificaci√≥n en una parte del c√≥digo que del cual dependen muchas otras funciones y temo olvidar contemplar alg√∫n caso e introducir un bug.

El **punto 3** suele ser mitigado usando **branching** usando *GIT* en lugar de *SVN* y realizando una integraci√≥n/merge manual de los distintas funcionalidades desarrolladas por los programadores.

Para evitar el **punto 8** a veces terminamos creando un nuevo m√©todo especificamente para el cambio que debo introducir, quedando as√≠ 2 m√©todos (el original y el nuevo) **con una misma responsabilidad, seguramente con c√≥digo duplicado** y que, el d√≠a de ma√±ana cuando volvamos a leerlo, no entendemos por qu√© raz√≥n est√° hecho as√≠. Esto es un **Anti-patr√≥n**.

Tambi√©n nombro algunas **ventajas** del testing:
1. Los tests de c√≥digo sirven como documentaci√≥n del mismo. Sabemos concretamente que escenarios est√°n cubiertos y cuales no.


Hay varios tipos de tests:

### ‚úîÔ∏è Unit tests
* Son muy chicos, est√°n dise√±ados para probar una parte espec√≠fica del c√≥digo y son los que m√°s abundan. 
* No deben llamar dependencias ni levantar spring context, h2 o consultar un WebService (esto ya ser√≠a Integration Tests), ya que deben ser super rapidos. 
* Si pueden usar MockUps.
* Deben testear entre un 70-80% del c√≥digo. 
* La l√≥gica del negocio deber√≠a probarse aqu√≠ dice el Guru. (Me parece raro, yo imagin√© que ser√≠a en los tests de Integraci√≥n, pero tal vez debamos pasarle los inputs necesarios para simular el contexto al test unitario)

### ‚úÖ Integration tests
* Tienen un scope m√°s grande que los tests unitarios.
* Pueden incluir Spring Context, consultas a BD u otros servicios.
* Consecuentemente son mucho m√°s lentos.
* En la proporci√≥n hay mucha menor cantidad.

### üßë‚Äçü¶Ø Functional tests
* Es cuando est√°s probando la aplicaci√≥n andando en alg√∫n ambiente, no una parte del c√≥digo.
* Pueden ser automatizados con frameworks de automatizaci√≥n como Selenium.
* Generalmente se prueban funcionalidades, por ej: WebServices, enviar y recibir mensajes, procesamiento de informaci√≥n, etc.
* En la proporci√≥n, conforman el menor porcentaje de los tests ya que son comparativamente muy lentos.
* Deber√≠amos usarlos solo para probar funcionalidad cr√≠tica.

### ‚ùå Errores comunes
* Mezclar Unit Tests con Integration Tests.
* Muchos tests levantando Spring Context: el build se vuelve lent√≠simo.
* Un test unitario no deber√≠a preocuparse por levantar el contexto necesario para ejecutar un escenario, sino solo que un m√©todo devuelva una cierta salida dadas unas condiciones de entrada. Es decir, no prueba un escenario con DATOS REALES sino que verifica que una funci√≥n hace su trabajo.
* En cambio un Test de integraci√≥n SI prueba un escenario. Levanta el contexto/configuraci√≥n y carga datos de un escenario real que deber√≠a poder llevarse a cabo.

### üí° Tips
* "I'm not a great programmer. I'm just a good programmer with great habits" - Kent Beck.
* Si hay tests que pueden hacen fallar a la aplicaci√≥n una vez que el desarrollo de una funcionalidad est√° finalizado, entonces esos tests deber√≠an formar parte del ciclo de desarrollo.

### Code coverage
Es el porcentaje de l√≠neas de c√≥digo que son testeadas


## Test-Driven Development (TDD)
Consiste en primero escribir el Test y luego desarrollar el c√≥digo.
El Test se escribe directamente cuando ni siquiera las clases han sido creadas, por lo que estar√° "lleno de errores".
La idea es que a medida que implementamos la funcionalidad el Test deber√≠a "corregirse" solo y cuando hayamos finalizado la implementaci√≥n, el test deber√≠a dar OK.

**Objetivo**: "Clean code that Works".

### Ciclo de TDD
1. **Escribir el test**: pensar como deber√≠a funcionar (dise√±ar).
2. **Hacer que cumpla el test**: Implementar *rapidamente* el c√≥digo que pasa el test.
3. **Hacerlo bien**: Refactorizar el c√≥digo mejorando la calidad.

Podemos usar una *TO-DO List* para poner items que la implementaic√≥n debe cumplir. Estas a su vez, se transformar√°n en Tests que deber√° pasar.

Si a√∫n sentis que no entendiste TDD al 100%, cosa que es completamente normal, te recomiendo fuertemente leer [este art√≠culo](http://www.jamesshore.com/v2/blog/2005/red-green-refactor) que hizo *James Shore* en donde lo explica **m√°s cercano a la realidad y f√°cil de entender**.

### :bulb: Tips
* Se puede m√°s de una assertion por test.
* Puede ser √∫til poner un assertEquals y un assertNotEquals para contemplar m√°s casos.
* equals() por defecto compara las ubicaciones de memoria, pero generalmente vamos a querer sobreescribirlo para saber si dos objetos son **conceptualmente** iguales. EJ: 2 personas con el mismo DNI, son iguales.
* Mejor que borrar un test porque ya no se usa, es deshabilitarlo comentando la raz√≥n. Ejemplo:
```java
@Test
@Ignore("Null values no longer allowed")
public void testDistinctOfSourceWithExceptionsFromKeySelector() 
```


## JUnit 5
### Configuraci√≥n
* Recomienda **maven surefire** 2.22.0 o superior! Este plugin se encarga de ejecutar los tests unitarios mediante Maven. Lo mismo para **maven-failsafe-plugin**.
* Para manejar las versiones pone dentro del <properties> del *pom.xml* una property llamada <junit-plataform.version> y luego al invoca como variable `$junit-plataform.version` en el campo *version* de las otras dependencias.
* A las dependencias de JUnit les pone la property <scope>test</scope>. Esto hace que los tests no se compilan dentro del .jar. [Mas info: Maven Scopes](https://www.baeldung.com/maven-dependency-scopes)
* 

### Tips
* Podemos crear un metodo *setUp* con @BeforeEach que se ejecuta **antes de cada test** de esa clase e inicializar Objetos y variables que se usan dentro de los Tests. Viene a ser como una especie de "contexto" que se levanta con cada clase de Tests. Algunas ventajas son:
  * Evita duplicar c√≥digo.
  * Util para levantar Mocks.
  * Aumenta la velocidad de ejecucion de los tests.
  * Los objetos estos deben ser atributos de clase, no variables internas al m√©todo *setUp*.
* Hay mas anotaciones de este estilo, las cuales forman el *ciclo de vida de JUnit*:
```java
@BeforeAll public static void beforeClass(){} // Solo se ejecuta una vez antes de todos los Tests
    @BeforeEach void setUp(){}
        @Test void myFirstTest(){}
    @AfterEach void tearDown(){} 
@AfterAll void afterClass(){} // Solo se ejecuta una vez al final
```
* Hay FRAMEWORKS especializados en *assertions*. Por ejemplo, para manejar JSONs:
  * **AssertJ**: agrega funcionalidad muy copada, por ejemplo, contiene una funcion `isXmlEqualToContentOf(File f)` que permite comparar un XML generado contra un ejemplo fijo. Esto puede resultar muy util para los casos de prueba contra JDE.
  * Hamcrest
  * Truth
* Hay algunas assertions especiales:
  * `fail()` --> Para asegurar que algo no se rompa podemos hacer if (condicion) {fail()}
  * `assertThrows()` o **assertDoesNotThrow()** --> Para asegurar que se est√°n manejando bien las excepciones
  * `assertTimeout()` --> Para asegurar que un m√©todo tarde menos de un cierto tiempo. No es muy usado ya que esto puede variar por muchos factores.
* `@Disabled(value = "Necesitamos hacer un mock para probar esto")`
* Podemos usar `@DisplayName("Debe tirar una excepcion si el tipo de cambio es negativo")` para mostrar un nombre amistoso

### Probar las excepciones esperadas
Muchas veces solo testeamos el camino feliz, pero es necesario probar tambi√©n que estamos controlando los errores/excepciones adecuadamente.
Para esto est√° el m√©todo `assertThrows(ExampleExcepction.class, () -> {C√≥digo que produce la excepci√≥n})`

### Testing timeouts
Probar los tiempos sirve para varias cosas, entre ellas, para asegurar que no hemos metido ning√∫n bug de performance.

**Es importante tener en cuenta que los tiempos pueden variar de un entorno al otro y quiz√°s un test que pasaba en nuestra pc, no pasa en el ambiente de CI.**
Para estos podemos usar 2 metodos:
```java
assertTimeout() // Ejecuta el test y una vez que termin√≥ se fija si excedi√≥ el tiempo estipulado o no.
assertTimeoutPreemptively() // Este ejecuta el test en otro hilo y aborta su ejecuci√≥n una vez que se super√≥ el timeout
```

### Ejecuci√≥n opcional de tests
Podemos hacer que los tests se ejecuten solo bajo algunas condiciones. Hay varias formas de hacerlo:
* Assumptions
* Annotations
```java
@EnabledOnOS
@EnabledOnJre
@EnabledIfEnvironmentVariable(name = "USER", matches = "juancruz") // Esta es la m√°s utilizada
// etc
```

#### Assumptions
Son presunciones. Nos permite evaluar si se cumple una condici√≥n antes de ejecutar un test. Generalmente son √∫tiles para evaluar variables de entorno y/o configuraciones del ambiente en el que se est√° corriendo el test y en base a eso, decidir si se ejecuta un test o no.

Dado que permiten decidir si se ejecuta o no, generalmente son las primeras lineas de los tests unitarios **aunque esto no es necesario**. Es posible tener m√°s de una assumption.

Si no se cumple la condici√≥n el test ser√° marcado como **ignorado**, no como fallado.
`assumeTrue("TEST".equals(System.getenv("env")))`

## Testing avanzado (con JUnit)
* Se puede usar `@Tag` y `@DisplayName` para mejorar el nombre visible del test. **Tag** sirve basicamente para agrupar Tests. Luego podemos decirle a a IntelliJ IDEA que ejecute *todos los tests con el tag "Controllers"* desde *Launch configurations*.
* `@Nested` permite definir una clase de Test dentro de otra. Sirve para agrupar Tests.
* Interfaces para los Tests? Al pedo.
* `@TestInstance(TestInstance.LifeCycle.PER_CLASS` Se utiliza a nivel de clase para definir el scope del `@BeforeAll`

## @RepeatedTest
`@RepeatedTest(value=10, name="{displayName}: {currentRepetition} of {totalRepetitions}")` nos permite hacer que un test se ejecute **n** veces seguidas, ajustando el par√°metro **value**. Por otro lado, **name** es el formato en el que se muestran las ejecuciones de los tests. Cuando usamos esta annotation no hace falta agregar `@Test` al m√©todo.

Tambi√©n pueden usarse unos par√°metros que nos brindan informaci√≥n extra. Estos son: ***TestInfo***, ***RepetitionInfo*** y ***TestReporter***.

### Casos de uso
* Imagino que es √∫til cuando quer√©s probar que una cierta funcionalidad **mantiene un estado** y **cumple con las restricciones impuestas**. Por ejemplo, *"un Club puede tener como m√°ximo 2 miembros"*:
```java
// Instancio alg√∫n objeto fuera del TestUnitario (por ej, en @BeforeAll) para que la instancia mantenga el estado entre un test y el otro

@RepetatedTest(3)
private void whenMembersGreaterThan2_expectClubIsFullException(RepetitionInfo repetitionInfo) {
    if (club.getMembersCount() < 2) {
        int expected = club.getMembersCount() + 1;
        club.addMember(new Member("Juan"));
        assertTrue(club.getMembersCount(), expected);
    } else {
        MyException thrown = assertThrows(
            MyException.class,
            () -> club.addMember(new Member("Juan"))
        );

        assertTrue(thrown.getMessage().contains("Stuff"));
    }
}
// Si bien en este caso no us√© repetitionInfo, podr√≠a imaginar un caso parecido a este.
```

## @ParameterizedTest
Es parecedio a `@RepeatedTest` ya que repite el test por cada conjunto de par√°metros que le pasamos.

```java
@ParameterizedTest
@ValueSource(strings = {"Juan", "Cruz"})
void testValueSource(String value) {
    System.out.println(value);
}

@ParameterizedTest
@EnumSource(CarType.class)
void testEnumSource(CarType carType) {
    // Corre el test una vez por cada Enum que est√© definido en la clase CarType
    System.out.println(carType);
}

public class enum {
  	SPORT, DELUXE;
}
```

### Usando un archivo CSV como fuente de datos
Corre el test una vez por cada tupla en el archivo csv que se encuentra en la carpeta `resources/input.csv`.

El par√°metro `numLinesToSkip` evita que lea el header del csv como una tupla

```java
@ParameterizedTest
@CsvFileSource(resources = "/input.csv", numLinesToSkip = 1)
void testCsvFileSource(String stateName, int val1, int val2) {
    System.out.println(stateName + val1 + val2);
}
```

### Usando m√©todos como fuente de datos
Corre el test una vez por cada tupla que devuelva el m√©todo `getargs()` definido a continuaci√≥n.

Esto nos da la ventaja de poder obtener los par√°metros de alguna forma no "estandarizada" por JUnit, por ejemplo, desde la BD, desde un JSON, un XML, etc.

Adem√°s lo podemos reutilizar en distintos tests.

```java
@DisplayName("Method Provider Test")
@ParameterizedTest(name = "{displayName} - [{index}] {arguments}")
@MethodSource("getargs")
void fromMethodTest(String stateName, int val1, int val2) {
    System.out.println(stateName + val1 + val2);
}

static Stream<Arguments> getargs() {
    return Stream.of(
            	Arguments.of("AR", 1, 1),
            	Arguments.of("BR", 2, 3)
    );
}
```

Tambi√©n podemos externalizar los datos de prueba a una clase utilizando `@ArgumentsSource`. No tengo en claro en qu√© escenarios resultar√≠a c√≥modo esto, pero quiz√°s sea cuando necesitamos agrupar un gran n√∫mero de argumentos para representar un escenario en particular.

```java
@DisplayName("Custom Provider Test")
@ParameterizedTest(name = "{displayName} - [{index}] {arguments}")
@ArgumentsSource(CustomArgsProvider.class)
void fromCustomProviderTest(String stateName, int val1, int val2) {
    System.out.println(stateName + val1 + val2);
}

public class CustomArgsProvider implements ArgumentsProvider {
    @Override
    public Stream<? extends Arguments> provideArguments(ExtensionContext extContext) throws Exception {
        return Stream.of(
            	Arguments.of("AR", 1, 1),
            	Arguments.of("BR", 2, 3)
        );
    }
}
```


## Tests unitarios vs Tests de Integraci√≥n
**Maven** usa con convenci√≥n en el nombre de las clases de test para saber cu√°l es un **Test de integraci√≥n**. Para detecte nuestra clase de test como tal, debemos nombrarla con el sufijo **IT** (que viene de *Integration Test*). Por ejemplo: `UsersServiceIT.java`

Ac√° dejo un [articulo super recomendado](^reflectoring) sobre este tema.

[^reflectoring]: https://reflectoring.io/spring-boot-web-controller-test/#unit-or-integration-test


## Tipos de test seg√∫n su capa (Controller, service, etc)
Una vez que ya estemos m√°s adentrados dentro del mundo del testing seguramente nos pongamos a pensar **¬øEst√° bien que est√© verificando esto ac√°?** Y lo cierto es que depender√° del contexto...

### Service (Business Logic) o Casos de uso (UseCase en arquitectura hexagonal)
Que se debe probar aqui:
- Que las llamadas a los m√©todos o servicios necesarios fueron realizadas solo la cantidad de veces necesarias.
- L√≥gica de negocio: idealmente todos los escenarios posibles
- Idealmente: todas las combinaciones de inputs posibles

Que NO se debe probar:
- Llamadas a APIs o servicios de terceros: usar un mock con la respuesta esperada
- Recuperar los datos de la BD: usar un mock con la respuesta esperada


### Controller (Request & Response format)
> NOTA: utilizar `@WebMvcTest(controllers = RegisterRestController.class)` se considera como un ***falso* test de integraci√≥n** porque levanta el contexto de spring pero solo para el controlador que le indicamos.

Que se debe probar aqu√≠:
- Request: Verbo HTTP, body, parametros, content-type, headers, Validaciones (si usas Bean Validators `@Valid`)
- Response: C√≥digo de estado, formato, content-type, headers
- Serializaci√≥n y deserializaci√≥n: usar una instancia real del object mapper, no un mock.
- Respuestas ante errores
- Middleware, Interceptors HTTP o ControllerAdvice: aunque esto es debatible, en mi opinion se debe levantar una instancia real de cada uno al probar los distintos endpoints para que en la request/response se refleje cualquier validaci√≥n o modificaci√≥n que estos hagan, por ej: validar que un usuario est√° autorizado o que en la request se env√≠a un determinado header. Otra opci√≥n es hacer otra clase de test especificamente para esto *(Ver nota m√°s abajo).

Que NO se debe probar:
- L√≥gica de negocio. En su lugar usar Mocks de los servicios con la respuesta esperada.

>**NOTA**:
> 
> La desventaja de probar los `ControllerAdvice` en una clase aparte (en vez de instanci√°ndolo en la del controlador) es que la respuesta que obtengas en el test del controller **puede ser diferente** a la que obtengas si haces una prueba de escritorio con la aplicaci√≥n andando.

#### Links de interes
- SUPER RECOMENDADO: https://reflectoring.io/spring-boot-web-controller-test/


### View (Front-end)
Esto es un mundo completamente diferente y por ahora queda fuera del alcance. S√© que hay al menos 2 enfoques a grandes rasgos:

- **Manual**: que una persona (QA) levante la aplicaci√≥n y pruebe todas las funciones manualmente para asegurarse que anda todo bien.
- **Tests automatizados**: generalmente se usa ***Selenium*** o alg√∫n software similar que simulan a un usuario utilizando el navegador web y siguiendo una serie de pasos
- **Tests unitarios**: por lo que entiendo esto no se usa mucho en front-end, pero en *Typescript* son los archivos terminados en `.spec.ts`. Estos mismos archivos son utilizados para hacer tests en *NodeJS* junto con el framework ***Jest***.


### API Client (o Adapter)
Basicamente solo podemos probar que la respuesta de la API **siga respetando el contrato** con el cual la integramos.

Contemplemos un poco la situaci√≥n a la hora de testear esto:
1. Si corremos los tests contra endpoints reales (ej: QA), dependemos de que estos est√©n disponibles para que los tests pasen. Esto **puede ser un problema** cuando tenemos un *pipeline* de CI/CD que no nos permite avanzar si los tests no pasan (EJ: mvn release)
2. Si corremos los tests contra *Mock-ups* evitaremos tener este problema, pero por otro lado, si nos modifican el contrato **no nos daremos cuenta que se rompi√≥** hasta que hagamos la prueba de escritorio o test de integraci√≥n.
3. Por los problemas mencionados anteriormente, lo m√°s pr√°ctico es hacer las pruebas manualmente en un ambiente de testing. En algunos casos estas pruebas pueden automatizarse

**Queda pendiente investigar herramientas de *Test Automation***

## Extensiones de JUnit
Hay una librer√≠a propia de JUnit que ofrece extensiones b√°sicas como `BeforeTestExecutionCallback` y `AfterTestExecutionCallback` que pueden resultar √∫tiles para medir los tiempos de un Test.
*Spring* y *Mockito* usan estas extensiones para agregar funcionalidad.

```java
import guru.springframework.sfgpetclinic.junitextensions.TimingExtension;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;

@ExtendWith(TimingExtension.class)
class PetTypeSDJpaServiceIT {
    @Test
    void findAll() {
    }
}


import org.junit.jupiter.api.extension.AfterTestExecutionCallback;
import org.junit.jupiter.api.extension.BeforeTestExecutionCallback;
import org.junit.jupiter.api.extension.ExtensionContext;

/**
 * Original source - https://junit.org/junit5/docs/current/user-guide/#extensions-lifecycle-callbacks-timing-extension
 */
public class TimingExtension implements BeforeTestExecutionCallback, AfterTestExecutionCallback {

    private static final Logger logger = Logger.getLogger(TimingExtension.class.getName());

    private static final String START_TIME = "start time";

    @Override
    public void beforeTestExecution(ExtensionContext context) throws Exception {
        getStore(context).put(START_TIME, System.currentTimeMillis());
    }

    @Override
    public void afterTestExecution(ExtensionContext context) throws Exception {
        Method testMethod = context.getRequiredTestMethod();
        long startTime = getStore(context).remove(START_TIME, long.class);
        long duration = System.currentTimeMillis() - startTime;

        logger.info(() -> String.format("Method [%s] took %s ms.", testMethod.getName(), duration));
    }

    private ExtensionContext.Store getStore(ExtensionContext context) {
        return context.getStore(ExtensionContext.Namespace.create(getClass(), context.getRequiredTestMethod()));
    }
}
```

## Ejecuci√≥n de Tests
* Se puede limitar la cantidad de tests con *Surefire* poniendo en `<group>` los **Tags** del grupo de tests que queremos ejecutar y/o excluir.
* **CircleCI** es el framework de *Continuous Integration* utilizado por el chabon del curso.


## Mockito
* Es el framework de testing mas popular para "mockear" o simular objetos.
* Est√° pensado para reemplazar a los objetos reales con objetos de prueba en los tests unitarios.
* Funciona bien con **inyecci√≥n de dependencias** (y por lo tanto con Spring), **evit√°ndo tener que levantar *Spring Context*** (lo que convertir√≠a al test unitario en un "test de integraci√≥n").
* P√°gina oficial: [https://site.mockito.org/](https://site.mockito.org/)
* Art√≠culo hecho por los autores: [¬øC√≥mo escribir buenos tests con Mockito?](https://github.com/mockito/mockito/wiki/How-to-write-good-tests)

### Tipos de Mocks
Se definen diferentes tipos de mocks:
1. **Dummy:** se usa solo para que el c√≥digo compile pero nunca es llamado. El t√≠pico caso donde una funci√≥n tiene m√°s argumentos de los que vamos a testear.
2. **Fake:** es un objeto que tiene una implementaci√≥n pero no se usa en producci√≥n. **¬øEjemplo?**
3. **Stub:** un objeto con respuestas pre-definidas en sus m√©todos. Por ejemplo, una instancia *Person* en particular.
4. **Mock:** un objeto con respuestas pre-definidas en sus m√©todos pero adem√°s puede tener l√≥gica implementada para simular comportamiento e incluso lanzar excepciones si se produce algo il√≥gico.
5. **Spy:** es un wrapper para el Mock que permite interceptar las llamadas al mock e inspeccionar el estado del objeto.

### M√°s terminolog√≠a
* **Verify:** se usa para verificar el numero de veces que el m√©todo de un mock ha sido llamado.
* **Argument matcher:** no explica como se usa. **COMPLETAR**
* **Argument captor:** permite interceptar los argumentos del m√©todo del mock seg√∫n su valor. Esto nos permite agregar l√≥gica al m√©todo del mock basado en los argumentos.

### Ejemplos B√°sicos
```java
public class MockTest {

	@Test
	void testInlineMock() {
		Map mapMock = mock(Map.class); // Inicializaci√≥n de un mock por defecto
		assertEquals(mapMock.size(), 0);
	}


	@Mock
	Map<String, Object> mapMock2;

	@BeforeEach
	void setUp() {
		MockitoAnnotations.initMocks(this); // Inicializa todos los mocks indicados con @Mock
	}

	@Test
	void testAnnotatedMock() {
		assertEquals(mapMock2.size(), 0);
	}
}

// MockitoExtension corre un BeforeEach inicializando los mocks, por lo tanto nos ahorra el trabajo de escribirlo en cada test
@ExtendWith(MockitoExtension.class)
public class MockitoExtensionTest {
	@Mock
	Map<String, Object> mapMock2;

	@Test
	void testAnnotatedMock() {
		assertEquals(mapMock2.size(), 0);
	}
}
```

### Inyectando dependencias y retornando valores con *when*
En el siguiente ejemplo vamos a ver como levanto un service que depende de un repository y como podemos inyectar las dependencias en el service con Mockito. 

Otra ventaja de estos mocks es que **no levantan el contexto de spring**, lo que hace que *"sigan siendo tests unitarios"* super r√°pidos.

En la funci√≥n `findByIdTest()` utilizo la funci√≥n `when()` y `thenReturn()` para indicar el valor que quiero retornar cuando una funci√≥n sea llamada. Y esta funci√≥n pertenece, justamente, a la dependencia que acabo de mockear con `@Mock` *"SpecialtyRepository"* la cual al ser un Mock, no sabe qu√© responder hasta que yo se lo indico de esta manera.

```java
import static org.mockito.Mockito.times;
import static org.mockito.Mockito.verify;

@ExtendWith(MockitoExtension.class)
public class SpecialitySDJpaServiceTest {

    @Mock
    SpecialtyRepository specialtyRepository;

    @InjectMocks // Inyecta los @Mocks necesarios en este service para sastisfacer las dependencias (algo que normalmente hace spring)
    SpecialitySDJpaService service;

    @Test
    void delete() {
        Speciality speciality = new Speciality();
        service.delete(speciality);
        // Verifica que se llam√≥ solo 1 vez el m√©todo delete en el repository.
        verify(specialtyRepository, times(1)).delete(speciality);
    }

    @Test
    void deleteById() {
        Speciality speciality = new Speciality();
        service.deleteById(speciality.getId());
    }

    @Test
    void findByIdTest() {
        Speciality speciality = new Speciality();
        when(specialtyRepository.findById(1L)).thenReturn(Optional.of(speciality)); // Defino el comportamiento del Mock
        Speciality foundSpeciality = specialtyRepository.findById(1L);
        assertThat(foundSpeciality).isNotNull();
        verify(specialtyRepository).findById(1L); // Verifica que se llam√≥ solo 1 vez el m√©todo findById.
    }
}
```

**Prestar especial atenci√≥n a los objetos que se est√°n mockeando:** un error com√∫n es hacer un Mock de la clase que estamos probando, lo que carece de sentido. Es como hacer un examen a carpeta abierta.

En el ejemplo de arriba, si en vez de mockear el **repository** mockearamos el **service**, que es la clase que estamos probando, eso estaria mal. Siempre se deben mockear **las dependencias**, nunca funciones propias de la clase o funcionalidad que estamos probando.

Como habremos notado, la funci√≥n `verify()` de *Mockito* no parece realmente servir de algo al verificar que realmente se llam√≥ al *Repository* luego de hacer el `delete`. Adem√°s, al usarlo est√°s "atando" el test a _la implementaci√≥n particular del repository_ que est√°s usando. Y esto **puede que te obligue a corregir** esa parte del test si haces un *refactor* sobre el repository. Es decir, agrega un overhead.

En otros escenarios donde s√≠ nos interesa hacer una verificaci√≥n m√°s minuciosa, espcialmente en alg√∫n ***Test de integraci√≥n***, este m√©todo si nos puede resultar √∫til. Dejo el link a [este thread](https://stackoverflow.com/questions/12539365/when-to-use-mockito-verify) de StackOverflow en donde justamente se discute esto y explican m√°s detalladamente lo que acabo de decir.



## Behaviour Driven Development (BDD)
Este enfoque se centra en que **los tests prueben los escenarios posibles** y no que el c√≥digo sea necesariamente super-robusto. Es decir, lo opuesto a **property-based testing (PBT)**.
Considera a los tests unitarios como *"la especificaci√≥n del comportamiento del programa"*.

Para definir los escenarios propone usar la keywords *given, when, then*, y los nombres de lo m√©todos de test deben ser oraciones, ej `saveValidPerson()`.
Ac√° muestro dos ejemplos equivalentes (el segundo est√° escrito en BDD), pero la funcionalidad es la misma:
```java
@ExtendWith(MockitoExtension.class)
public class SpecialitySDJpaServiceTest {
    @Test
    void findByIdTest() {
        Speciality speciality = new Speciality();
        when(specialtyRepository.findById(1L)).thenReturn(Optional.of(speciality));
        Speciality foundSpeciality = specialtyRepository.findById(1L);
        assertThat(foundSpeciality).isNotNull();
        verify(specialtyRepository).findById(1L);
    }

    @Test
    void findByIdTest() { // BDD
        // given
        Speciality speciality = new Speciality();
        given(specialtyRepository.findById(1L)).willReturn(Optional.of(speciality)); 
        
        // when
        Speciality foundSpeciality = specialtyRepository.findById(1L);
        
        // then
        assertThat(foundSpeciality).isNotNull();
        then(specialtyRepository).should(times(1)).findById(1L);
    }
}
```

Como vemos, BDD es solo una cuesti√≥n de enfoque y nomenclatura, no va m√°s all√° de ello. Personalmente creo que es √∫til tener tanto tests que verifiquen que un en m√©todo en particular funcione coherentemente (sin pensar en si se va a usar en ese escenario o no), como tests que verifiquen los escenarios o "la l√≥gica del negocio".

Adem√°s, a menudo nos encontramos con que no podemos probar un m√©todo de manera aislada porque est√° como privado (`private`), sin embargo estaremos prob√°ndolo si cubrimos todos los escenarios posibles para una funcionalidad "padre" la cual consume este m√©todo privado. (Para m√°s info, ver nota al final)

## Mockito avanzado

### Excepciones
En el curso da un ejemplo donde mockea un *Repository* para que lanze una excepci√≥n en un determinado caso. Si bien esto no parece tener demasiado sentido, debemos recordar que cuando mockeamos un objeto es porque necesitamos probar otra funcionalidad que depende en parte del objeto mockeado. Entonces **podemos mockear una excepci√≥n si, por ejemplo, queremos ver si una porci√≥n del c√≥digo est√° atajando bien las excepciones.**

Un ejemplo concreto que se me ocurre podr√≠a ser:
> Supongamos que tenemos 10 productos en stock y quiero vender 50. 
> 
> Deber√≠a testear que en caso de que esto ocurra, se lanza una excepci√≥n de que no hay suficiente stock **y que esta excepci√≥n es correctamente capturada por qui√©n hizo la llamada al m√©todo**, mostrando un mensaje amistoso para el usuario.

Podemos probar esto **mockeando la excepci√≥n de que no hay suficiente stock** y hacer un test para verificar que capturamos y tratamos bien la excepci√≥n.

*Mockito* soporta esto tanto para **TDD** como para **BDD**.

### Capturar argumentos con *Argument Captor*
Sirve para capturar los argumentos que se le pasan a una funci√≥n, que no necesariamente tiene que ser la misma funci√≥n que llamamos desde el c√≥digo del test, sino que puede ser una que es llamada indirectamente.
Podemos usarla para agregar alguna *assertion* sobre un par√°metro, el cual esperamos que sea uno en particular o que sea modificado de una cierta forma.

El ejemplo que se da en el curso es el siguiente:
```java
public class OwnerController {
    // ...
    public String processFindForm(Owner owner, BindingResult result, Model model) {
        // ....
        List<Owner> results = ownerService.findAllByLastNameLike("%" + owner.getLastName() + "%");
        if (results.isEmpty()) {
            result.rejectValue("lastName", "notFound", "not found");
            return "owners/findOwners"; // Esto es una vista
        } else if (results.size() == 1) {
            owner = results.get(0);
            return "redirect/:owners/" + owner.getId();
        } else {
            model.addAttribute("selections", results);
            return "owners/ownersList";
        }
    }
}

@ExtendWith(MockitoExtension.class)
public class OwnerControllerTest {
    @Mock
    OwnerService ownerService;

    @Mock
    BindingResult bindingResult;

    @InjectMocks
    OwnerController controller;

    @Captor
    ArgumentCaptor<String> stringArgumentCaptor;

    // 1
    @Test
    void processFindFormWildcardString() {
        //given
        Owner owner = new Owner(1l, "Joe", "Buck");
        List<Owner> ownerList = new ArrayList<>();
        final ArgumentCaptor<String> captor = ArgumentCaptor.forClass(String.class);
        given(ownerService.findAllByLastNameLike(captor.capture())).willReturn(ownerList);

        //when
        String viewName = controller.processFindForm(owner, bindingResult, null);

        //then
        assertThat("%Buck%").isEqualToIgnoringCase(captor.getValue());
    }

    // 2. Otra forma de hacer lo mismo pero utilizando el @Captor
    @Test
    void processFindFormWildcardStringAnnotation() {
        //given
        Owner owner = new Owner(1l, "Joe", "Buck");
        List<Owner> ownerList = new ArrayList<>();
        given(ownerService.findAllByLastNameLike(stringArgumentCaptor.capture())).willReturn(ownerList);

        //when
        String viewName = controller.processFindForm(owner, bindingResult, null);

        //then
        assertThat("%Buck%").isEqualToIgnoringCase(stringArgumentCaptor.getValue());
    }
}
```


### Answers
Son otra manera de hacer los mocks. Basicamente nos permite usar una funci√≥n lambda para definir el comportamiento de nuestor Mock. Si se usa bien, puede ayudar a generar c√≥dgio limpio dentro de los tests. El [ejemplo que da en el curso](https://github.com/springframeworkguru/tb2g-bdd-mockito/blob/answers/src/test/java/guru/springframework/sfgpetclinic/controllers/OwnerControllerTest.java) est√° bastante bueno: hace un mock de un `Service` que var√≠a su respuesta seg√∫n el parametro (usa *argument captor*) para poder probar un m√©todo en espec√≠fico (`processFindForm`) que es el retorna la URL de la p√°gina a cargar.

```java
// ...
@BeforeEach
void setUp() {
    given(ownerService.findAllByLastNameLike(stringArgumentCaptor.capture()))
            .willAnswer(invocation -> {
        List<Owner> owners = new ArrayList<>();

        String name = invocation.getArgument(0);

        if (name.equals("%Buck%")) {
            owners.add(new Owner(1l, "Joe", "Buck"));
            return owners;
        } else if (name.equals("%DontFindMe%")) {
            return owners;
        } else if (name.equals("%FindMe%")) {
            owners.add(new Owner(1l, "Joe", "Buck"));
            owners.add(new Owner(2l, "Joe2", "Buck2"));
            return owners;
        }

        throw new RuntimeException("Invalid Argument");
    });
}

@Test
void processFindFormWildcardFound() {
    //given
    Owner owner = new Owner(1l, "Joe", "FindMe");

    //when
    String viewName = controller.processFindForm(owner, bindingResult, Mockito.mock(Model.class));

    //then
    assertThat("%FindMe%").isEqualToIgnoringCase(stringArgumentCaptor.getValue());
    assertThat("owners/ownersList").isEqualToIgnoringCase(viewName);
}
// ...
```

### Verificar orden de ejecuci√≥n
La clase `InOrder` nos permite declarar el orden en que deben **verificarse** las interacciones, es decir, el orden en el que se ejecutar√° el `Mockito.verify`. Es posible testear c√≥digo sin usar esto, aunque no est√° de m√°s agregar estas restricciones en casos donde s√≠ tiene sentido. El objetivo de esto entiendo que viene al tratar de evitar que un cambio posterior introduzca sin querer un bug, como cualquier otro test. A continuaci√≥n dejo un ejemplo **real** extra√≠do de la librer√≠a de Google *Guava*:

```java
@Test
public void testAddDelayedShutdownHook_success() throws InterruptedException {
    TestApplication application = new TestApplication();
    ExecutorService service = mock(ExecutorService.class);
    application.addDelayedShutdownHook(service, 2, TimeUnit.SECONDS);
    verify(service, Mockito.never()).shutdown();
    application.shutdown();
    InOrder shutdownFirst = Mockito.inOrder(service);
    shutdownFirst.verify(service).shutdown();
    shutdownFirst.verify(service).awaitTermination(2, TimeUnit.SECONDS);
}
```

Para ver el c√≥digo fuente en GitHub [click aqu√≠.](https://github.com/google/guava/blob/13f703c25f43bda8935b28e7b481de48d6b9bc1b/guava-tests/test/com/google/common/util/concurrent/MoreExecutorsTest.java#L570)

Tambi√©n puede agregarse al final el m√©todo `inOrder.verifyNoMoreInteractions()` y `verifyZeroInteractions(object)` para agregar a√∫n m√°s restricciones. Este √∫ltimo puede usarse en cualquier parte del test, entonces podemos usarlo para decir "hasta este momento no se llam√≥ a este objeto" y verificar m√°s adelante en el tiempo s√≠ se hicieron llamadas.


### Spies
Los esp√≠as son como **"Mock parciales"** ya que, salvo que hagamos un mock de un m√©todo espec√≠fico, el esp√≠a ejecutara el m√©todo **real**. El uso de esp√≠as est√° desaconsejado salvo en casos donde realmente sea muy √∫til, por ejemplo c√≥digo de terceros o que no podemos cambiar facilmente. ¬øPor qu√©? Porque es m√°s f√°cil seguro ejecutar el c√≥digo real que construir un Mock que pueda no comportarse exactamente como el c√≥digo.

```java
    List list = new LinkedList();
    List spy = spy(list);

    //optionally, you can stub out some methods:
    when(spy.size()).thenReturn(100);

    //using the spy calls *real* methods
    spy.add("one");
    spy.add("two");

    //prints "one" - the first element of a list
    System.out.println(spy.get(0));

    //size() method was stubbed - 100 is printed
    System.out.println(spy.size());

    //optionally, you can verify
    verify(spy).add("one");
    verify(spy).add("two");
```

**Cuidado con usar el `thenReturn()` ya que este no funciona con los Spy. Usar `doReturn()`. Ejemplo:**
```java
    List list = new LinkedList();
    List spy = spy(list);

    //Impossible: real method is called so spy.get(0) throws IndexOutOfBoundsException (the list is yet empty)
    when(spy.get(0)).thenReturn("foo");
    // Puedo usar esto para aclararlo de forma explicita. ESTO NO HACE NADA, ES SOLO PARA FACILITAR LA LECTURA.
    when(spy.someMethod()).thenCallRealMethod();

    //You have to use doReturn() for stubbing
    doReturn("foo").when(spy).get(0);
```


## Spring Framework
Aqu√≠ voy a mencionar algunas de las herramientas que nos proporciona *Spring*, no *Springboot* para testing.

### Mocks
* Environment
* JDNI
* Servlet API
* Spring Web Reactive

Para usarlos es necesario a√±adir `@SpringJUnitConfig` a nuestra clase de test.

### ReflectionTestUtils
`ReflectionTestUtils` es una clase que nos permite testear m√©todo privados de una clase, entre otras cosas. M√°s abajo, en la secci√≥n de dudas, hay un ejemplo.

### Spring MVC Test
Provee herramientas para testear los controladores sin necesidad de levantar el contexto de Spring, lo que nos permite hacer **tests unitarios** sobre los controladores.
* `MockHttpServletRequest`: para request y responses.
* `MockHttpSession`
* `ModelAndViewAssert`

### Tests de Integracion

[Aqui dejo un articulo](https://dzone.com/articles/integration-testing-in-spring-boot-1) que muestra ejemplos claros y practicos de como hacer tests de integracion con *Springboot*.

* Spring cachea el contexto entre tests para levantar m√°s r√°pido el contexto.
* Permite inyectar beans en clases de test.
* Por defecto, hace rollback de todas las transacciones de Base de Datos.
* Spring automaticamente crea una instancia de `JdbcTemplate` que junto con `JdbcTestsUtils` nos da algunas herramientas para hacer tests.
* Soporta varias BD embebidas, entre las cuales H2 parece ser la mejor: H2, HSQL, Derby.

**Voy a intentar aplicar esto y hablar√© m√°s al respecto cuando ya tenga alguna experiencia.**


### Context class configuration
* Con la annotation de clase `@SpringJUnitConfig(classes = {LaurelConfig.class})` podemos especificar el contexto a levantar para nuestra clase de test. En [este ejemplo](https://github.com/springframeworkguru/tb2g-testing-spring/blob/component-scan/src/test/java/org/springframework/samples/petclinic/sfg/junit5/HearingInterpreterLaurelTest.java) podemos ver como al elegir esa configuraci√≥n, *Spring* ya sabr√° que componente levantar en `HearingIntepreter` y por eso podemos usar el `@Autowired`.
* Tambi√©n est√° la posibilidad de definir un `@Configuration` dentro de la misma clase de test, donde se puede configurar manualmente cuales *Beans* se van a levantar. Ver [Ejemplo](https://github.com/springframeworkguru/tb2g-testing-spring/blob/component-scan/src/test/java/org/springframework/samples/petclinic/sfg/junit5/HearingInterpreterInnerClassTest.java).
    * Tambi√©n se puede hacer autom√°ticamente con `@ComponentScan("com.package")`. Ver [Ejemplo](https://github.com/springframeworkguru/tb2g-testing-spring/blob/component-scan/src/test/java/org/springframework/samples/petclinic/sfg/junit5/HearingInterpreterComponentScanTest.java).

**NOTA: Al usar `@ComponentScan`, SpringBoot buscar√° configuraciones tanto en los packages de *test* como en los de *src*. Debemos asegurarnos de que no se generan conflictos aqu√≠ ya que puede llevar a comportamientos indeseados.**


### Active profiles
Otra manera de configurar el contexto el con *profiles*. Por ejemplo, imaginemos que tenemos una suerte de patr√≥n *Strategy* y varias clases de implementaciones de la estrategia con `@Component`. Entonces agregamos `@Profile("uno")` a la primera implementaci√≥n y `@Profile("dos")` a la segunda.

Luego desde una clase de Test podemos levantar una de esas implementaciones utilizando `@ActiveProfiles("uno")`. Podemos verlo en [este ejemplo](https://github.com/springframeworkguru/tb2g-testing-spring/tree/active-profile/src/test/java/org/springframework/samples/petclinic/sfg/junit5)

----

## ‚ùì Dudas 
* ¬øCu√°ndo es √∫til usar `@RepeatedTest`?
* ¬øCu√°ndo es √∫til usar `@ArgumensProvider`?
* ¬øCu√°ndo es √∫til usar **Arguments Matcher**?
* No entiendo para qu√© es el Maven Surefire Plugin. ¬øHace que aparezca la opci√≥n test en el ciclo de vida maven?
* Tampoco el Maven Failsafe Plugin. Por lo que veo, sin esos plug-ins, no se VE en la consola la corrida de los tests. Ambos son para generar reportes. Por alguna raz√≥n los Tests de Integraci√≥n los ejecuta con este plugin en **mvn verify** poniendo como **goals** `<goals><goal>integration-test<goal><goal>verify<goal><goals>`. Estos plugins se usan junto con maven-site plugin y configurando la seccion `<reporting>` del *pom.xml*.

### ‚úîÔ∏è ¬øC√≥mo pruebo un m√©todo privado?
Hay varios enfoques interesantes en cuanto a esto:

**[Algunos dicen](https://stackoverflow.com/a/34586)** que la mejor forma es probar un m√©todo privado es a trav√©s de otro m√©todo publico que lo llame. Y que si esto no se puede hacer, se da una de las siguientes condiciones:
1. El m√©todo privado es c√≥digo muerto (nunca se utiliza).
2. Hay un problema de dise√±o en la clase que est√°s testeando.
3. El m√©todo no deber√≠a ser privado. **ACLARACION: Un m√©todo nunca deber√≠a ser forzado a ser p√∫blico con el √∫nico fin de poder testearlo.**

Sin embargo, si consideramos que el m√©todo privado amerita un testing m√°s exhaustivo, podemos valernos de algunas herramientas para ejecutar ese m√©todo privado **sin convertirlo en p√∫blico**:

#### Usando Java Reflection
```java
Method method = TargetClass.getDeclaredMethod(methodName, argClasses);
method.setAccessible(true);
return method.invoke(targetObject, argObjects);

// Para atributos de clase privados
Field field = TargetClass.getDeclaredField(fieldName);
field.setAccessible(true);
field.set(object, value);
```

#### Usando Springboot
```java
import org.springframework.test.util.ReflectionTestUtils;

// ...

@Test
    public void whenNoAfipValidation_thenAddWarning() {
        ArrayList<ValidationProcess> validationProcesses = new ArrayList<>();
        validationProcesses.add(new ValidationProcess("TOTAL", "", 0, true, "com.besysoft.validationsmanagement.validationprocess.CalculateTotalValidation"));
        Object result = ReflectionTestUtils.invokeMethod(service, "hasAnyAfipValidation", validationProcesses);
        if (result instanceof Boolean) {
            boolean hasAfipValidation = (boolean) result;
            assertEquals(false, result);
        } else
            fail();
    }

```

Tambi√©n existe una librer√≠a **[PowerMock](https://www.baeldung.com/powermock-private-method)** que permite hacerlo de una manera similar a las 2 anteriores. De todas maneras, recalco que en mi opinion, no se deben hacer tests sobre m√©todos privados exceptos casos puntuales.

### ‚úîÔ∏è ¬øQu√© sentido tiene testear un Service que lo √∫nico que hace es llamar a un Repository?
Es la pregunta que siempre me hice. Uno de los instructores responde pero no da un escenario de la vida real:
()[https://www.udemy.com/course/testing-spring-boot-beginner-to-guru/learn/lecture/12562476#questions/5700521]

"La verdad es que se usa solo en TDD, ya que se escribe primero el test y luego el c√≥digo."

### ¬øC√≥mo pruebo un repository o DAO?
Primero que nada, aclarar que si levantamos el *spring context* el test pasar√° a ser considerado ***de integraci√≥n*** y no ***unitario***. Por ello, en la medida de lo posible, aprovechar cada vez que se levanta el *spring context* para correr **varios** tests de integracion.

Para responder esta pregunta [aqu√≠ dejo hay un art√≠culo](https://howtodoinjava.com/best-practices/how-you-should-unit-test-dao-layer/) que muestra un ejemplo y lo explica bastante bien, aunque me permito hacer algunas notas:

1. Tener en cuenta que el ejemplo est√° hecho en JUnit 4, no JUnit 5.
2. Alli propone un *archivo de configuracion especifico para test* donde logicamente estara apuntando a una BD, otra opcion interesante es levantar una BD en memoria (por ejemplo, *H2*) para que no necesitemos tener una BD levantada solo para poder compilar.
3. Si vamos a agregar tests para los *controllers*, no har√° falta agregar tests individuales para el DAO ya que, [podemos aprovechar los tests de integracion para probar desde el *controller* hasta el *DAO*](https://dzone.com/articles/integration-testing-in-spring-boot-1).

## Links a art√≠culos interesantes
- [Utilidades para testing provistas por *Springboot*](https://docs.spring.io/spring-framework/docs/current/reference/html/testing.html)
- [Buenas practicas de tests unitarios (JUnit)](https://howtodoinjava.com/best-practices/unit-testing-best-practices-junit-reference-guide/)